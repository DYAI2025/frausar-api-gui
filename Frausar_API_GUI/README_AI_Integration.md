# Frausar AI-Integration - Phase 1

## Ãœbersicht

Die Frausar AI-Integration erweitert das bestehende Frausar-System um AI-gestÃ¼tzte Datenanalyse und -bereinigung. Phase 1 implementiert einen vollstÃ¤ndigen Data Cleaning Agent mit sowohl GUI- als auch FastAPI-Schnittstelle.

## ğŸ—ï¸ Architektur

```
Frausar AI-Integration
â”œâ”€â”€ agents/                 # AI-Agenten
â”‚   â”œâ”€â”€ base_agent.py      # Basis-Agenten-Klasse
â”‚   â”œâ”€â”€ data_cleaning_agent.py  # Data Cleaning Agent
â”‚   â””â”€â”€ supervisor_agent.py     # Agenten-Orchestrierung (Stub)
â”œâ”€â”€ api/                   # FastAPI-Integration
â”‚   â”œâ”€â”€ main.py           # Haupt-API-Anwendung
â”‚   â””â”€â”€ models.py         # Pydantic-Modelle
â”œâ”€â”€ services/             # Shared Services
â”‚   â”œâ”€â”€ data_service.py   # Zentrale Datenhaltung
â”‚   â”œâ”€â”€ agent_service.py  # Agenten-Verwaltung
â”‚   â””â”€â”€ config_service.py # Konfigurationsverwaltung
â”œâ”€â”€ data/                 # Daten-Verzeichnisse
â”‚   â”œâ”€â”€ uploads/          # Hochgeladene Dateien
â”‚   â”œâ”€â”€ results/          # Verarbeitete Ergebnisse
â”‚   â””â”€â”€ demo_data.csv     # Beispiel-Daten
â”œâ”€â”€ start_ai_integration.command  # One-Click-Start
â”œâ”€â”€ start_ai_tests.command        # One-Click-Tests
â””â”€â”€ main_ai_integration.py # Hauptskript
```

## ğŸš€ Installation

### Voraussetzungen

- Python â‰¥3.10
- pip (Python Package Manager)

### AbhÃ¤ngigkeiten installieren

```bash
cd Frausar_API_GUI
pip install -r requirements_ai.txt
```

### ZusÃ¤tzliche AbhÃ¤ngigkeiten (falls nicht in requirements_ai.txt)

```bash
pip install fastapi uvicorn pandas numpy openpyxl pyyaml requests
```

## ğŸ¯ Verwendung

### 1. One-Click-Start (Empfohlen)

#### Hauptsystem starten
```bash
# Doppelklick auf:
_STARTING_/start_ai_integration.command
```

#### Tests ausfÃ¼hren
```bash
# Doppelklick auf:
_STARTING_/start_ai_tests.command
```

### 2. Manueller Start

```bash
cd Frausar_API_GUI
python main_ai_integration.py
```

Das System startet:
- FastAPI-Server auf `http://localhost:8000`
- Konsolen-Interface fÃ¼r Phase 1
- Alle Services und Agenten

### 3. API-Zugriff

#### API-Dokumentation
- Swagger UI: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

#### VerfÃ¼gbare Endpunkte

##### Datei-Upload
```bash
curl -X POST "http://localhost:8000/upload" \
     -H "accept: application/json" \
     -H "Content-Type: multipart/form-data" \
     -F "file=@demo_data.csv"
```

##### Datenbereinigung starten
```bash
curl -X POST "http://localhost:8000/clean" \
     -H "accept: application/json" \
     -H "Content-Type: application/json" \
     -d '{"filename": "20250101_120000_demo_data.csv"}'
```

##### Ergebnisse abrufen
```bash
curl -X GET "http://localhost:8000/result" \
     -H "accept: application/json"
```

##### System-Status
```bash
curl -X GET "http://localhost:8000/status" \
     -H "accept: application/json"
```

##### Agenten-Status
```bash
curl -X GET "http://localhost:8000/agent/data_cleaning/status" \
     -H "accept: application/json"
```

### 4. Python-Client Beispiel

```python
import requests
import pandas as pd

# API-Basis-URL
BASE_URL = "http://localhost:8000"

# 1. Datei hochladen
with open("demo_data.csv", "rb") as f:
    files = {"file": f}
    response = requests.post(f"{BASE_URL}/upload", files=files)
    upload_data = response.json()
    filename = upload_data["filename"]

# 2. Datenbereinigung starten
clean_request = {"filename": filename}
response = requests.post(f"{BASE_URL}/clean", json=clean_request)

# 3. Ergebnisse abrufen
response = requests.get(f"{BASE_URL}/result")
result_data = response.json()

# 4. Daten als DataFrame laden
df = pd.DataFrame(result_data["data_preview"])
print(f"Bereinigte Daten: {result_data['total_rows']} Zeilen, {result_data['total_columns']} Spalten")
```

## ğŸ¤– AI-Agenten

### DataCleaningAgent

Der DataCleaningAgent fÃ¼hrt automatische Datenbereinigung durch:

#### Funktionen
- **Fehlende Werte behandeln**: Automatische AuffÃ¼llung basierend auf Datentyp
- **Datentypen konvertieren**: Intelligente Erkennung und Konvertierung
- **Duplikate entfernen**: Automatische Duplikatserkennung
- **AusreiÃŸer behandeln**: IQR-basierte AusreiÃŸererkennung
- **Spalten mit zu vielen fehlenden Werten entfernen**: Konfigurierbare Schwellenwerte

#### Konfiguration

```yaml
data_cleaning:
  remove_columns_with_missing_threshold: 0.4  # 40% fehlende Werte
  fill_numeric_with: "mean"                   # mean, median, mode
  fill_categorical_with: "mode"               # mode, most_frequent
  remove_duplicates: true
  handle_outliers: true
  outlier_threshold: 3.0                      # Standardabweichungen
  convert_dtypes: true
  log_changes: true
```

### SupervisorAgent (Stub)

Der SupervisorAgent ist fÃ¼r Phase 2+ vorgesehen und wird die Orchestrierung mehrerer Agenten Ã¼bernehmen.

## ğŸ“Š Datenformate

### UnterstÃ¼tzte Eingabeformate
- **CSV** (.csv)
- **Excel** (.xlsx, .xls)
- **JSON** (.json)

### Ausgabeformate
- **CSV** (Standard)
- **Excel** (.xlsx)
- **JSON** (.json)

## âš™ï¸ Konfiguration

### Konfigurationsdateien

Das System verwendet YAML-Konfigurationsdateien im `config/`-Verzeichnis:

- `agents.yaml` - Agenten-Konfigurationen
- `api.yaml` - API-Einstellungen
- `gui.yaml` - GUI-Einstellungen
- `data.yaml` - Datenverwaltung

### Standard-Konfigurationen

```yaml
# api.yaml
host: "0.0.0.0"
port: 8000
debug: false
cors_origins: ["*"]

# data.yaml
upload_dir: "data/uploads"
result_dir: "data/results"
temp_dir: "data/temp"
max_file_size: 104857600  # 100MB
```

## ğŸ”§ Entwicklung

### Projektstruktur erweitern

#### Neuen Agenten hinzufÃ¼gen

1. Neue Agenten-Klasse erstellen:
```python
from agents.base_agent import BaseAgent

class MyCustomAgent(BaseAgent):
    async def process(self, data, **kwargs):
        # Implementierung
        return result
```

2. Agenten registrieren:
```python
from services import get_agent_service

agent_service = get_agent_service()
agent_service.register_agent("my_custom", MyCustomAgent())
```

#### Neue API-Endpunkte hinzufÃ¼gen

1. Endpunkt in `api/main.py` hinzufÃ¼gen:
```python
@app.post("/my_endpoint")
async def my_endpoint(request: MyRequest):
    # Implementierung
    return MyResponse(...)
```

2. Pydantic-Modelle in `api/models.py` definieren:
```python
class MyRequest(BaseModel):
    # Request-Felder

class MyResponse(BaseModel):
    # Response-Felder
```

### Testing

#### Automatisierte Tests

```bash
# Tests ausfÃ¼hren
python -m pytest Frausar_API_GUI/tests/

# Spezifische Tests
python -m pytest Frausar_API_GUI/tests/test_agents.py
```

#### Manuelle Tests

1. Demo-Daten verwenden:
```bash
# Demo-Datenbereinigung starten
python main_ai_integration.py
# Option 4 wÃ¤hlen
```

2. API-Tests:
```bash
# API-Status prÃ¼fen
curl http://localhost:8000/status

# Demo-Upload
curl -X POST "http://localhost:8000/upload" \
     -F "file=@data/demo_data.csv"
```

#### One-Click-Tests

```bash
# Doppelklick auf:
_STARTING_/start_ai_tests.command
```

## ğŸ“ Logging

### Log-Dateien

- **Hauptlog**: `Frausar_API_GUI/logs/ai_integration.log`
- **API-Logs**: Uvicorn-Access-Logs (stdout)
- **Agenten-Logs**: Strukturierte Logs mit Metadaten

### Log-Level

- **INFO**: Standard-Informationen
- **DEBUG**: Detaillierte Debug-Informationen
- **WARNING**: Warnungen
- **ERROR**: Fehler

## ğŸš¨ Fehlerbehandlung

### HÃ¤ufige Fehler

1. **Port bereits belegt**
   ```
   LÃ¶sung: Port in api.yaml Ã¤ndern oder anderen Prozess beenden
   ```

2. **Datei nicht gefunden**
   ```
   LÃ¶sung: Pfad prÃ¼fen, Datei existiert
   ```

3. **Import-Fehler**
   ```
   LÃ¶sung: AbhÃ¤ngigkeiten installieren, Python-Pfad prÃ¼fen
   ```

### Debug-Modus

```bash
# Debug-Modus aktivieren
export DEBUG=true
python main_ai_integration.py
```

## ğŸ”® Phase 2+ Roadmap

### Phase 2: Erweiterte Agenten
- [ ] Data Wrangling Agent
- [ ] Visualization Agent
- [ ] Multi-Agenten-Orchestrierung
- [ ] GUI-Integration (Tkinter)

### Phase 3: Produktionsreife
- [ ] Authentifizierung
- [ ] Rate Limiting
- [ ] Docker-Container
- [ ] Monitoring & Metrics

### Phase 4: Erweiterte Features
- [ ] Marker-Generierung
- [ ] Repository-Analyse
- [ ] LangChain-Integration
- [ ] Cloud-Deployment

## ğŸ“ Support

### Dokumentation
- API-Docs: `http://localhost:8000/docs`
- Code-Dokumentation: Inline-Kommentare

### Logs analysieren
```bash
tail -f Frausar_API_GUI/logs/ai_integration.log
```

### Debug-Informationen
```bash
# System-Status
curl http://localhost:8000/status

# Agenten-Status
curl http://localhost:8000/agent/data_cleaning/status
```

## ğŸ“„ Lizenz

Teil des Frausar-Systems - ProprietÃ¤r 