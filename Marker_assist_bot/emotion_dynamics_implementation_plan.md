# üé≠ Emotionale Dynamikdetektion - Iterationsplan

**Projektname:** EmotionDynamics Integration f√ºr FRAUSAR  
**Erstellt am:** 21.07.2025  
**Version:** 1.0  

---

## üìã **√úBERBLICK**

### **Zielsetzung:**
Implementierung zeitlich sensitiver Emotionserkennung pro Sprecher zur Verfeinerung der Markerresonanz und Auffindung subtiler Dynamiken im Verlauf.

### **Integrationsebene:**
- **Ort:** `detectors/emotion_dynamics_detector.py`
- **Format:** Python-Modul im Stil bestehender Detektoren (DETECT_[NAME].py)
- **Integration:** Vollst√§ndige Einbindung in bestehendes FRAUSAR-Schema

---

## üéØ **DETAILLIERTER ITERATIONSPLAN**

### **PHASE 1: Foundation & Setup** ‚è±Ô∏è 2-3 Stunden

#### **Task 1.1: Umgebungsanalyse und Dependencies** (30 min)
- ‚úÖ **Analysiert:** Aktuelle DETECT.py Struktur verstanden
- ‚úÖ **Evaluiert:** Bestehende Marker-Integration-Patterns
- üîÑ **TODO:** EmotionDynamics/uedLib.py Requirements pr√ºfen
- üîÑ **TODO:** NRC VAD/EmoLex Verf√ºgbarkeit validieren

#### **Task 1.2: Verzeichnisstruktur erstellen** (15 min)
```
detectors/
‚îú‚îÄ‚îÄ emotion_dynamics_detector.py      # Hauptdetektor
‚îú‚îÄ‚îÄ emotion_utils/                    # Hilfsfunktionen
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ vad_calculator.py             # VAD-Berechnungen
‚îÇ   ‚îú‚îÄ‚îÄ movement_metrics.py           # Slope, Variance, etc.
‚îÇ   ‚îî‚îÄ‚îÄ emotion_models.py             # Datenmodelle
‚îî‚îÄ‚îÄ tests/
    ‚îî‚îÄ‚îÄ test_emotion_dynamics.py      # Unit Tests
```

#### **Task 1.3: Basis-Dependencies installieren** (30 min)
- NRC VAD Lexicon vorbereiten
- SentenceTransformers (falls n√∂tig)
- NumPy, SciPy f√ºr mathematische Berechnungen
- Requirements.txt erweitern

#### **Task 1.4: Template-Erstellung** (45 min)
- DETECT_EMOTION_DYNAMICS.py Grundstruktur
- BaseDetector-Klasse als Vorlage verwenden
- Schema-Integration vorbereiten

---

### **PHASE 2: Core Emotion Engine** ‚è±Ô∏è 4-5 Stunden

#### **Task 2.1: VAD-Berechnungsmodul** (2 Stunden)
```python
# emotion_utils/vad_calculator.py

class VADCalculator:
    def __init__(self, nrc_vad_path):
        self.load_nrc_vad_lexicon(nrc_vad_path)
    
    def calculate_text_vad(self, text: str) -> Dict[str, float]:
        """Berechnet Valenz, Erregung, Dominanz f√ºr Text"""
        # Tokenization + NRC VAD Lookup
        # Gewichteter Durchschnitt
        return {"valence": 0.0, "arousal": 0.0, "dominance": 0.0}
    
    def calculate_speaker_vad_sequence(self, messages: List[Dict]) -> List[Dict]:
        """VAD-Zeitreihe pro Sprecher"""
        pass
```

#### **Task 2.2: Bewegungsmetriken-Modul** (1.5 Stunden)
```python
# emotion_utils/movement_metrics.py

def calculate_slope(values: List[float], timestamps: List[datetime]) -> float:
    """Linear regression slope √ºber Zeitachse"""
    
def calculate_variance(values: List[float]) -> float:
    """Emotionale Volatilit√§t"""
    
def calculate_displacement(start_val: float, end_val: float) -> float:
    """Gesamtverschiebung"""
    
def calculate_volatility(values: List[float], window_size: int = 3) -> float:
    """Rolling-window Volatilit√§t"""
```

#### **Task 2.3: Datenmodelle definieren** (30 min)
```python
# emotion_utils/emotion_models.py

@dataclass
class EmotionPoint:
    timestamp: datetime
    speaker: str
    valence: float
    arousal: float
    dominance: float
    text: str
    
@dataclass
class EmotionDynamics:
    speaker: str
    window_start: datetime
    window_end: datetime
    valence_slope: float
    arousal_slope: float
    dominance_slope: float
    volatility: float
    displacement: float
    marker_triggered: Optional[str] = None
```

#### **Task 2.4: Testing Foundation** (1 Stunde)
- Unit Tests f√ºr VAD-Berechnungen
- Mock-Daten f√ºr Testing
- Baseline-Performance-Tests

---

### **PHASE 3: Detector Implementation** ‚è±Ô∏è 3-4 Stunden

#### **Task 3.1: DETECT_EMOTION_DYNAMICS Klasse** (2 Stunden)
```python
# detectors/emotion_dynamics_detector.py

import re
from typing import Dict, List
from datetime import datetime, timedelta
from .emotion_utils.vad_calculator import VADCalculator
from .emotion_utils.movement_metrics import *

DETECT_EMOTION_DYNAMICS_COMPONENTS = {
    "EMO_SLOPE_UP": ["steigender Emotionstrend"],
    "EMO_SLOPE_DOWN": ["fallender Emotionstrend"], 
    "EMO_VOLATILE": ["emotionale Volatilit√§t"],
    "EMO_CONTRAST_DRIFT": ["emotionaler Kontrastwechsel"]
}

def detect_emotion_dynamics(conversation_chunk: List[Dict], 
                           window_minutes: int = 30,
                           min_messages: int = 5) -> Dict:
    """
    Hauptdetektor f√ºr emotionale Dynamiken
    
    Args:
        conversation_chunk: Liste von Nachrichten mit ts, speaker, text, markers
        window_minutes: Zeitfenster in Minuten
        min_messages: Mindestanzahl Nachrichten pro Sprecher
    
    Returns:
        Dict mit erkannten emotionalen Markern
    """
    
    results = {
        "is_detected": False,
        "emotion_markers": [],
        "speaker_dynamics": {},
        "confidence_score": 0.0
    }
    
    # Gruppiere nach Sprecher
    speaker_messages = group_by_speaker(conversation_chunk)
    
    for speaker, messages in speaker_messages.items():
        if len(messages) < min_messages:
            continue
            
        # VAD-Sequenz berechnen
        vad_sequence = calculate_vad_sequence(messages)
        
        # Bewegungsmetriken
        dynamics = analyze_emotion_movement(vad_sequence, window_minutes)
        
        # Trigger-Logik
        triggered_markers = check_trigger_conditions(dynamics)
        
        if triggered_markers:
            results["is_detected"] = True
            results["emotion_markers"].extend(triggered_markers)
            results["speaker_dynamics"][speaker] = dynamics
    
    return results

# Trigger-Schwellwerte
SLOPE_THRESHOLD = 0.15
VOLATILITY_THRESHOLD = 0.5
CONTRAST_THRESHOLD = 1.2

def check_trigger_conditions(dynamics: EmotionDynamics) -> List[str]:
    """Pr√ºft welche emotionalen Marker ausgel√∂st werden"""
    markers = []
    
    # Steigender Trend
    if dynamics.valence_slope > SLOPE_THRESHOLD:
        markers.append("EMO_SLOPE_UP")
    
    # Fallender Trend  
    if dynamics.valence_slope < -SLOPE_THRESHOLD:
        markers.append("EMO_SLOPE_DOWN")
        
    # Hohe Volatilit√§t
    if dynamics.volatility > VOLATILITY_THRESHOLD:
        markers.append("EMO_VOLATILE_WINDOW")
        
    # Kontrastwechsel
    if abs(dynamics.displacement) > CONTRAST_THRESHOLD:
        markers.append("EMO_CONTRAST_DRIFT")
    
    return markers
```

#### **Task 3.2: Integration in Marker-System** (1 Stunde)
- Schema-Update f√ºr neue Emotion-Marker
- Integration in DETECT_default_marker_schema.yaml
- Verbindung zu bestehenden Markern

#### **Task 3.3: Rollierende Anwendung** (1 Stunde)
- Zeitbasierte Trigger (alle X Minuten/Nachrichten)
- Integration in marker_matcher Pipeline
- Kompatibilit√§t mit bestehenden Detektoren

---

### **PHASE 4: Advanced Features & Integration** ‚è±Ô∏è 2-3 Stunden

#### **Task 4.1: Marker-Kombinationen** (1 Stunden)
```python
# Integration mit bestehenden Markern
EMOTION_MARKER_COMBINATIONS = {
    "C_ADAPTIVE_POLARIZATION + EMO_VOLATILE": "EMOTIONAL_CHAOS_PATTERN",
    "MM_MEANING_CRISIS + EMO_SLOPE_DOWN": "DEEPENING_DEPRESSION_RISK", 
    "C_INNER_EMPTINESS + EMO_MEAN_LOW": "CHRONIC_LOW_MOOD_PATTERN"
}

def detect_combined_patterns(emotion_results: Dict, 
                           existing_markers: List[str]) -> List[str]:
    """Erkennt Kombinationsmuster zwischen Emotion und bestehenden Markern"""
    pass
```

#### **Task 4.2: Konfigurationssystem** (30 min)
```yaml
# emotion_dynamics_config.yaml
emotion_detection:
  window_minutes: 30
  min_messages_per_speaker: 5
  triggers:
    slope_threshold: 0.15
    volatility_threshold: 0.5
    contrast_threshold: 1.2
  
marker_combinations:
  enabled: true
  priority_combinations:
    - ["C_ADAPTIVE_POLARIZATION", "EMO_VOLATILE"]
    - ["MM_MEANING_CRISIS", "EMO_SLOPE_DOWN"]
```

#### **Task 4.3: Performance-Optimierung** (30 min)
- Caching f√ºr VAD-Berechnungen
- Efficient sliding-window implementation
- Memory management f√ºr gro√üe Conversations

#### **Task 4.4: Driftachsen-Integration** (30 min)
- Verbindung zu driftachsen_kompakt.yaml
- Emotionale Dichte f√ºr Risiko-Drift-Muster
- Kalibrierung von Risk-Levels (green/yellow/blinking/red)

---

### **PHASE 5: Testing & Documentation** ‚è±Ô∏è 2-3 Stunden

#### **Task 5.1: Comprehensive Testing** (1.5 Stunden)
```python
# tests/test_emotion_dynamics.py

def test_vad_calculation():
    """Teste VAD-Berechnung mit bekannten Werten"""
    
def test_slope_detection():
    """Teste Trend-Erkennung"""
    
def test_volatility_measurement():
    """Teste Volatilit√§ts-Berechnung"""
    
def test_full_emotion_detection():
    """End-to-End Test mit simulierten Gespr√§chen"""
    
def test_marker_integration():
    """Teste Integration in bestehende Marker-Pipeline"""
```

#### **Task 5.2: Dokumentation** (1 Stunden)
- API-Dokumentation
- Konfigurations-Guide
- Beispiel-Anwendungen
- Performance-Benchmarks

#### **Task 5.3: GUI-Integration** (30 min)
- Button f√ºr Emotion-Dynamics-Analyse
- Visualisierung von Emotional-Trends
- Konfiguration √ºber GUI

---

## üîß **VALIDIERUNG UND QUALIT√ÑTSSICHERUNG**

### **Effizienz-Kriterien:**
‚úÖ **Modularit√§t:** Separate Utils, klare Interfaces  
‚úÖ **Performance:** O(n) f√ºr VAD-Berechnung, O(n log n) f√ºr Sliding-Window  
‚úÖ **Skalierbarkeit:** Unterst√ºtzt beliebige Gespr√§chsl√§ngen  
‚úÖ **Integration:** Nahtlos in bestehendes FRAUSAR-System  

### **Nachhaltigkeit-Kriterien:**
‚úÖ **Konfigurierbar:** Schwellwerte und Fenster anpassbar  
‚úÖ **Erweiterbar:** Neue Emotion-Metriken einfach hinzuf√ºgbar  
‚úÖ **Testbar:** Umfassende Unit-Test-Coverage  
‚úÖ **Dokumentiert:** Vollst√§ndige API- und User-Dokumentation  

---

## üìä **ERWARTETE OUTPUTS**

### **Neue Marker-Klassen:**
- `EMO_SLOPE_UP` / `EMO_SLOPE_DOWN`
- `EMO_VOLATILE_WINDOW`  
- `EMO_MEAN_LOW`
- `EMO_CONTRAST_DRIFT`

### **MarkerPacket Format:**
```json
{
  "speaker": "B",
  "marker": "EMO_SLOPE_UP", 
  "score": 0.76,
  "window": "2025-07-21T10:00:00 ‚Üí 2025-07-21T10:30:00",
  "details": {
    "valence_slope": 0.32,
    "arousal_slope": 0.18, 
    "dominance_slope": 0.05,
    "volatility": 0.45,
    "displacement": 0.67
  }
}
```

### **Integration Points:**
- ‚úÖ DETECT_default_marker_schema.yaml
- ‚úÖ frausar_gui.py (neuer Button)
- ‚úÖ marker_matcher.py (Pipeline-Integration)
- ‚úÖ Bestehende Marker-Kombinationen

---

## ‚è∞ **ZEITSCH√ÑTZUNG**

| Phase | Dauer | Kritischer Pfad |
|-------|--------|------------------|
| Phase 1 | 2-3h | VAD-Setup |
| Phase 2 | 4-5h | Core-Engine |
| Phase 3 | 3-4h | Detector-Implementierung |
| Phase 4 | 2-3h | Advanced-Features |
| Phase 5 | 2-3h | Testing & Docs |
| **TOTAL** | **13-18h** | **2-3 Arbeitstage** |

---

## üöÄ **N√ÑCHSTE SCHRITTE**

1. **Plan-Validierung**: Review und Approval des Plans ‚úÖ
2. **Phase 1 Start**: Umgebung und Dependencies setup 
3. **Iterative Entwicklung**: Kleine Schritte mit kontinuierlichem Testing
4. **Integration Testing**: Nahtlose Einbindung in FRAUSAR
5. **Produktive Nutzung**: Rollout f√ºr Live-Marker-Detection

**Ready to begin implementation!** üéØ 